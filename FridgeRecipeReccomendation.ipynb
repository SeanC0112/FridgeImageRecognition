{
  "nbformat": 4,
  "nbformat_minor": 0,
  "metadata": {
    "colab": {
      "provenance": [],
      "gpuType": "T4",
      "authorship_tag": "ABX9TyPHg4dpbo1ywiecregV51mu",
      "include_colab_link": true
    },
    "kernelspec": {
      "name": "python3",
      "display_name": "Python 3"
    },
    "language_info": {
      "name": "python"
    },
    "accelerator": "GPU"
  },
  "cells": [
    {
      "cell_type": "markdown",
      "metadata": {
        "id": "view-in-github",
        "colab_type": "text"
      },
      "source": [
        "<a href=\"https://colab.research.google.com/github/SeanC0112/FridgeImageRecognition/blob/main/FridgeRecipeReccomendation.ipynb\" target=\"_parent\"><img src=\"https://colab.research.google.com/assets/colab-badge.svg\" alt=\"Open In Colab\"/></a>"
      ]
    },
    {
      "cell_type": "markdown",
      "source": [
        "Importing dependencies and basic functions for the Segment Anything model\n",
        "from https://colab.research.google.com/github/facebookresearch/sam2/blob/main/notebooks/automatic_mask_generator_example.ipynb#scrollTo=c3e9a446-0d12-4b6f-ba93-03fe7453ace7\n"
      ],
      "metadata": {
        "id": "JTeUERe4TN1E"
      }
    },
    {
      "cell_type": "code",
      "source": [
        "import torch\n",
        "import torchvision\n",
        "print(\"PyTorch version:\", torch.__version__)\n",
        "print(\"Torchvision version:\", torchvision.__version__)\n",
        "print(\"CUDA is available:\", torch.cuda.is_available())\n",
        "import sys\n",
        "!{sys.executable} -m pip install opencv-python matplotlib\n",
        "!{sys.executable} -m pip install 'git+https://github.com/facebookresearch/sam2.git'\n",
        "\n",
        "!mkdir -p images\n",
        "!wget -P images https://raw.githubusercontent.com/facebookresearch/sam2/main/notebooks/images/cars.jpg\n",
        "\n",
        "!mkdir -p ../checkpoints/\n",
        "!wget -P ../checkpoints/ https://dl.fbaipublicfiles.com/segment_anything_2/092824/sam2.1_hiera_large.pt"
      ],
      "metadata": {
        "id": "WV1dUoGnS0CV"
      },
      "execution_count": null,
      "outputs": []
    },
    {
      "cell_type": "code",
      "source": [
        "import os\n",
        "os.environ[\"PYTORCH_ENABLE_MPS_FALLBACK\"] = \"1\"\n",
        "import numpy as np\n",
        "import torch\n",
        "import matplotlib.pyplot as plt\n",
        "from PIL import Image"
      ],
      "metadata": {
        "id": "qKDmwZGeU2JU"
      },
      "execution_count": null,
      "outputs": []
    },
    {
      "cell_type": "code",
      "source": [
        "# select the device for computation\n",
        "if torch.cuda.is_available():\n",
        "    device = torch.device(\"cuda\")\n",
        "elif torch.backends.mps.is_available():\n",
        "    device = torch.device(\"mps\")\n",
        "else:\n",
        "    device = torch.device(\"cpu\")\n",
        "print(f\"using device: {device}\")\n",
        "\n",
        "if device.type == \"cuda\":\n",
        "    # use bfloat16 for the entire notebook\n",
        "    torch.autocast(\"cuda\", dtype=torch.bfloat16).__enter__()\n",
        "    # turn on tfloat32 for Ampere GPUs (https://pytorch.org/docs/stable/notes/cuda.html#tensorfloat-32-tf32-on-ampere-devices)\n",
        "    if torch.cuda.get_device_properties(0).major >= 8:\n",
        "        torch.backends.cuda.matmul.allow_tf32 = True\n",
        "        torch.backends.cudnn.allow_tf32 = True\n",
        "elif device.type == \"mps\":\n",
        "    print(\n",
        "        \"\\nSupport for MPS devices is preliminary. SAM 2 is trained with CUDA and might \"\n",
        "        \"give numerically different outputs and sometimes degraded performance on MPS. \"\n",
        "        \"See e.g. https://github.com/pytorch/pytorch/issues/84936 for a discussion.\"\n",
        "    )"
      ],
      "metadata": {
        "id": "rFzaCA9SVJYc"
      },
      "execution_count": null,
      "outputs": []
    },
    {
      "cell_type": "code",
      "source": [
        "#function for showing the annotations over the original image\n",
        "np.random.seed(3)\n",
        "\n",
        "def show_anns(anns, borders=True):\n",
        "    if len(anns) == 0:\n",
        "        return\n",
        "    sorted_anns = sorted(anns, key=(lambda x: x['area']), reverse=True)\n",
        "    ax = plt.gca()\n",
        "    ax.set_autoscale_on(False)\n",
        "\n",
        "    img = np.ones((sorted_anns[0]['segmentation'].shape[0], sorted_anns[0]['segmentation'].shape[1], 4))\n",
        "    img[:, :, 3] = 0\n",
        "    for ann in sorted_anns:\n",
        "        m = ann['segmentation']\n",
        "        color_mask = np.concatenate([np.random.random(3), [0.5]])\n",
        "        img[m] = color_mask\n",
        "        if borders:\n",
        "            import cv2\n",
        "            contours, _ = cv2.findContours(m.astype(np.uint8), cv2.RETR_EXTERNAL, cv2.CHAIN_APPROX_NONE)\n",
        "            # Try to smooth contours\n",
        "            contours = [cv2.approxPolyDP(contour, epsilon=0.01, closed=True) for contour in contours]\n",
        "            cv2.drawContours(img, contours, -1, (0, 0, 1, 0.4), thickness=1)\n",
        "\n",
        "    ax.imshow(img)"
      ],
      "metadata": {
        "id": "lEhA8wxRVXKz"
      },
      "execution_count": null,
      "outputs": []
    },
    {
      "cell_type": "markdown",
      "source": [
        "Testing the model, code from: https://colab.research.google.com/github/facebookresearch/sam2/blob/main/notebooks/automatic_mask_generator_example.ipynb#scrollTo=ad354922"
      ],
      "metadata": {
        "id": "4yuQA4SNVsX4"
      }
    },
    {
      "cell_type": "code",
      "source": [],
      "metadata": {
        "id": "y9anPRysV0Xv"
      },
      "execution_count": null,
      "outputs": []
    }
  ]
}